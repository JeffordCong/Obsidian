#Unity 
## 1. NDC 空间反推

渲染管线的坐标变换流程通常是：模型空间 (Object Space) -> 世界空间 (World Space) -> 观察空间 (View Space) -> 裁剪空间 (Clip Space) -> NDC 空间 (Normalized Device Coordinates)。

要从深度反推世界坐标，我们需要逆转这个流程：NDC 空间 -> 裁剪空间 -> 观察空间 -> 世界空间。最直接高效的方法是利用 观察投影矩阵的逆矩阵 (Inverse View-Projection Matrix) 一步到位，直接从裁剪空间转换到世界空间。

以“远裁切面”为准，基于远裁剪面进行推导 mic

#### 1.1 重建 NDC 坐标

首先将屏幕空间坐标转换到 NDC 空间中。

```glsl
float4 ndcPos = (o.screenPos / o.screenPos.w) * 2 - 1;
```

然后将屏幕像素对应在摄像机远平面（Far plane）的点转换到[剪裁空间](https://zhida.zhihu.com/search?content_id=108643993&content_type=Article&match_order=1&q=%E5%89%AA%E8%A3%81%E7%A9%BA%E9%97%B4&zhida_source=entity)（Clip space）。因为在 NDC 空间中远平面上的点的 z 分量为 1，所以可以直接乘以摄像机的 Far 值来将其转换到剪裁空间（实际就是反向透视除法）。

```glsl
float far = _ProjectionParams.z;
float3 clipVec = float3(ndcPos.x, ndcPos.y, 1.0) * far;
```

接着通过[逆投影矩阵](https://zhida.zhihu.com/search?content_id=108643993&content_type=Article&match_order=1&q=%E9%80%86%E6%8A%95%E5%BD%B1%E7%9F%A9%E9%98%B5&zhida_source=entity)（Inverse Projection Matrix）将点转换到观察空间（View space）。

```glsl
float3 o.viewVec = mul(unity_CameraInvProjection, clipVec.xyzz).xyz;
```

已知在观察空间中摄像机的位置一定为（0，0，0），所以从摄像机指向远平面上的点的向量就是其在观察空间中的位置。

将向量乘以线性深度值，得到在深度缓冲中储存的值的观察空间位置。

```glsl
float depth = UNITY_SAMPLE_DEPTH(tex2Dproj(_CameraDepthTexture, i.screenPos));
float3 viewPos = i.viewVec * Linear01Depth(depth);
```

最后将观察空间中的位置变换到世界空间中。

```glsl
float3 worldPos = mul(UNITY_MATRIX_I_V, float4(viewPos, 1.0)).xyz;
```

#### 1.2 变换到世界空间

```hlsl
    float4 worldPosHomogeneous= mul(invViewProj, positionNDC);
    worldPosHomogeneous.xyz /= worldPosHomogeneous.w;
```

通过逆矩阵乘法，得到一个包含 w​ ​的世界空间齐次坐标，然后必须执行一次 /w​ 才能将它还原为真正的 3D 坐标。

```C#
half2 GetObjectSpeceByDepth(half2 positionCS, half3 positionVS)
{
    half2 screenUV = positionCS.xy / _ScreenParams.xy;
    half depthMap = SAMPLE_TEXTURE2D(_CameraDepthTexture, sampler_CameraDepthTexture, screenUV).r;
    half depth = LinearEyeDepth(depthMap, _ZBufferParams);

    // 深度重建观察空间
    float4 depthVS = 1;
    depthVS.z = depth;
    depthVS.xy = positionVS * depth / - positionVS.z;

    // 将观察空间深度转换为世界空间
    float3 depthWS = mul(unity_CameraToWorld, depthVS).xyz;
    float3 depthOS = mul(unity_WorldToObject, float4(depthWS, 1.0)).xyz;
    return depthOS.xz;
}
```

## 2. 相机射线法

此方法以近裁剪平面为准，根据观察空间深度值计算。

#### 2.1 2.1. 实现原理：

任何从摄像机中发出的、最终落在屏幕上的光线，都必然会穿过近裁剪面。所以从摄像机出发，穿过屏幕上任意一个像素的射线，可以由穿过摄像机视锥体四个近裁剪面角的四条射线，根据该像素在屏幕上的相对位置（UV 坐标）进行双线性插值得到。

坐标系中的一个顶点坐标可以通过它相对于另一个顶点坐标的偏移量来求得。也就是说，我们只需要知道:

摄像机在世界空间下的位置和世界空间下该像素相对于摄像机的偏移量，最后把他们相加就可以得到该像素的世界坐标。

worldPos = WorldSpaceCameraPos + LinearDepth \cdot interpolatedRay

- WorldSpaceCameraPos：是摄像机在世界空间下的位置，
    
- LinearDepth * interpolatedRay：计算出偏移量，
    
    - LinearDepth：是线性深度值，
    - interpolatedRay：是由顶点着色器输出并插值后得到的射线，它包含了该像素到摄像机的距离与方向信息。

#### 2.2 2.2. 步骤

###### 2.2.1 计算方向：

```c#
            var camera = renderingData.cameraData.camera;
            var cameraData = renderingData.cameraData;
            var cameraTransform = camera.transform;

            Matrix4x4 frustumCorners = Matrix4x4.identity;

            float fov = camera.fieldOfView;
            float near = camera.nearClipPlane;
            float aspect = camera.aspect;

            float halfHeight = near * Mathf.Tan(fov * 0.5f * Mathf.Deg2Rad);

            Vector3 toRight = cameraTransform.right * halfHeight * aspect;
            Vector3 toTop = cameraTransform.up * halfHeight;
            Vector3 topLeft = cameraTransform.forward * near + toTop - toRight;

            float scale = topLeft.magnitude / near;
            topLeft.Normalize();
            topLeft *= scale;

            Vector3 topRight = cameraTransform.forward * near + toRight + toTop;
            topRight.Normalize();
            topRight *= scale;

            Vector3 bottomLeft = cameraTransform.forward * near - toRight - toTop;
            bottomLeft.Normalize();
            bottomLeft *= scale;

            Vector3 bottomRight = cameraTransform.forward * near + toRight - toTop;
            bottomRight.Normalize();
            bottomRight *= scale;

            frustumCorners.SetRow(0, bottomLeft);
            frustumCorners.SetRow(1, bottomRight);
            frustumCorners.SetRow(2, topRight);
            frustumCorners.SetRow(3, topLeft);

 			 material.SetMatrix("_FrustumCornersRay", frustumCorners);
 			 cmd.Blit(source, destination, material, 0);
```

###### 2.2.2 确定距离 (Depth Buffer)

```c#
    half depthMap = SAMPLE_TEXTURE2D(_CameraDepthTexture, sampler_CameraDepthTexture, i.uv_depth);
    half linearDepth = LinearEyeDepth(depthMap, _ZBufferParams);
```

###### 2.2.3 最终合成

```c#
 half3 positionWS = _WorldSpaceCameraPos + linearDepth * i.interpolatedRay.xyz;
```